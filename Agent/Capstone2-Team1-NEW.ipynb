{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad279926",
   "metadata": {},
   "source": [
    "# Ti·ªÅn X·ª≠ L√Ω\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ed1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STT_Unnamed: 0_level_1', 'Ng√†y_Unnamed: 1_level_1', 'M√£_Unnamed: 2_level_1', 'Tham\\n chi·∫øu_Unnamed: 3_level_1', 'M·ªü \\nc·ª≠a_Unnamed: 4_level_1', 'ƒê√≥ng\\n c·ª≠a_Unnamed: 5_level_1', 'Cao\\nnh·∫•t_Unnamed: 6_level_1', 'Th·∫•p\\n nh·∫•t_Unnamed: 7_level_1', 'Trung\\n b√¨nh_Unnamed: 8_level_1', 'Thay ƒë·ªïi gi√°_+/-', 'Thay ƒë·ªïi gi√°_%', 'GD kh·ªõp l·ªánh_KL', 'GD kh·ªõp l·ªánh_GT', 'GD th·ªèa thu·∫≠n_KL', 'GD th·ªèa thu·∫≠n_GT', 'T·ªïng giao d·ªãch_KL', 'T·ªïng giao d·ªãch_GT', 'V·ªën h√≥a\\n th·ªã tr∆∞·ªùng_Unnamed: 17_level_1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ ƒê·ªçc file Excel g·ªëc\n",
    "# M·ªôt s·ªë file th·ªëng k√™ c·ªßa SSI, VNDIRECT, HNX... th∆∞·ªùng c√≥ 2 d√≤ng ti√™u ƒë·ªÅ ‚Üí ta g·ªôp l·∫°i\n",
    "df = pd.read_excel(\"FTS.xls\", header=[0, 1])\n",
    "\n",
    "# 2Ô∏è‚É£ G·ªôp 2 d√≤ng ti√™u ƒë·ªÅ th√†nh 1 chu·ªói t√™n c·ªôt duy nh·∫•t\n",
    "df.columns = ['_'.join([str(c).strip() for c in col if str(c) != 'nan']) for col in df.columns.values]\n",
    "\n",
    "# Ki·ªÉm tra t√™n c·ªôt sau khi g·ªôp\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6619d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"Ng√†y_Unnamed: 1_level_1\": \"Date\",\n",
    "    \"M·ªü \\nc·ª≠a_Unnamed: 4_level_1\": \"Open\",\n",
    "    \"ƒê√≥ng\\n c·ª≠a_Unnamed: 5_level_1\": \"Close\",\n",
    "    \"Cao\\nnh·∫•t_Unnamed: 6_level_1\": \"High\",\n",
    "    \"Th·∫•p\\n nh·∫•t_Unnamed: 7_level_1\": \"Low\",\n",
    "    \"T·ªïng giao d·ªãch_KL\": \"Volume\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7f3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Close\n",
      "0 2024-11-12  42.95\n",
      "1 2024-11-13  42.75\n",
      "2 2024-11-14  41.50\n",
      "3 2024-11-15  40.50\n",
      "4 2024-11-18  41.35\n",
      "5 2024-11-19  40.50\n",
      "6 2024-11-20  41.35\n",
      "7 2024-11-21  41.90\n",
      "8 2024-11-22  41.25\n",
      "9 2024-11-25  41.60\n"
     ]
    }
   ],
   "source": [
    "df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "import numpy as np\n",
    "\n",
    "# ƒê·ªïi ki·ªÉu d·ªØ li·ªáu ng√†y\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "print(df.head(10)[[\"Date\", \"Close\"]])\n",
    "\n",
    "# Lo·∫°i b·ªè d√≤ng tr·ªëng ho·∫∑c l·ªói\n",
    "df = df.dropna(subset=[\"Date\", \"Close\", \"Volume\"]).reset_index(drop=True)\n",
    "\n",
    "# N·∫øu d·ªØ li·ªáu Volume c√≥ k√Ω t·ª± ph√¢n c√°ch (vd: \"2,910,800\") th√¨ chuy·ªÉn v·ªÅ s·ªë\n",
    "df[\"Volume\"] = df[\"Volume\"].replace({\",\": \"\"}, regex=True).astype(float)\n",
    "df[\"Open\"] = df[\"Open\"].astype(float)\n",
    "df[\"High\"] = df[\"High\"].astype(float)\n",
    "df[\"Low\"] = df[\"Low\"].astype(float)\n",
    "df[\"Close\"] = df[\"Close\"].astype(float)\n",
    "\n",
    "# T√≠nh t·ª∑ su·∫•t sinh l·ª£i h·∫±ng ng√†y\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "\n",
    "# Trung b√¨nh ƒë·ªông (Moving Average)\n",
    "df[\"MA20\"] = df[\"Close\"].rolling(20).mean()\n",
    "df[\"MA50\"] = df[\"Close\"].rolling(50).mean()\n",
    "\n",
    "# RSI\n",
    "def calc_RSI(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = np.where(delta > 0, delta, 0)\n",
    "    loss = np.where(delta < 0, -delta, 0)\n",
    "    avg_gain = pd.Series(gain).rolling(period).mean()\n",
    "    avg_loss = pd.Series(loss).rolling(period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "df[\"RSI\"] = calc_RSI(df[\"Close\"])\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d37a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open  High    Low  Close     Volume    Return     MA20    MA50  \\\n",
      "0 2025-01-21  41.00  41.4  40.80  40.85  1097480.0  0.000000  41.3075  41.970   \n",
      "1 2025-01-22  41.05  41.1  40.70  40.70   986800.0 -0.003672  41.2400  41.925   \n",
      "2 2025-01-23  41.00  42.0  40.75  41.60  1988700.0  0.022113  41.1775  41.902   \n",
      "3 2025-01-24  41.60  41.7  41.25  41.40  1185700.0 -0.004808  41.1100  41.900   \n",
      "4 2025-02-03  40.95  41.4  40.80  40.90   971400.0 -0.012077  41.0150  41.908   \n",
      "\n",
      "         RSI  \n",
      "0  40.000000  \n",
      "1  38.235294  \n",
      "2  53.030303  \n",
      "3  58.333333  \n",
      "4  53.846154  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9c949",
   "metadata": {},
   "source": [
    "# Build ENV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e640268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv:\n",
    "    def __init__(self, data, initial_balance=100000):\n",
    "        self.data = data\n",
    "        self.initial_balance = initial_balance\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.cash = self.initial_balance\n",
    "        self.position = 0\n",
    "        self.current_step = 0\n",
    "        self.portfolio_values = []\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        return self.data.iloc[self.current_step]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        action: 'BUY', 'SELL', 'HOLD'\n",
    "        \"\"\"\n",
    "        price = self.data.iloc[self.current_step][\"Close\"]\n",
    "        \n",
    "        if action == \"BUY\" and self.cash >= price:\n",
    "            self.position += 1\n",
    "            self.cash -= price\n",
    "        elif action == \"SELL\" and self.position > 0:\n",
    "            self.position -= 1\n",
    "            self.cash += price\n",
    "        \n",
    "        portfolio_value = self.cash + self.position * price\n",
    "        self.portfolio_values.append(portfolio_value)\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        return self._get_state(), portfolio_value, done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe44f38",
   "metadata": {},
   "source": [
    "# Market Itelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6b3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≥m t·∫Øt th·ªã tr∆∞·ªùng hi·ªán t·∫°i t·ª´ d·ªØ li·ªáu (c√°c ch·ªâ b√°o) ƒë·ªÉ g·ª≠i cho Gemini.\n",
    "def build_market_summary(row):\n",
    "    text = (\n",
    "        f\"Ng√†y {row['Date'].date()} - \"\n",
    "        f\"Gi√° ƒë√≥ng c·ª≠a: {row['Close']:.2f}, \"\n",
    "        f\"MA20: {row['MA20']:.2f}, MA50: {row['MA50']:.2f}, \"\n",
    "        f\"RSI: {row['RSI']:.2f}. \"\n",
    "    )\n",
    "    if row['MA20'] > row['MA50']:\n",
    "        text += \"Xu h∆∞·ªõng ng·∫Øn h·∫°n: TƒÉng. \"\n",
    "    else:\n",
    "        text += \"Xu h∆∞·ªõng ng·∫Øn h·∫°n: Gi·∫£m. \"\n",
    "    if row['RSI'] > 70:\n",
    "        text += \"Th·ªã tr∆∞·ªùng ƒëang qu√° mua.\"\n",
    "    elif row['RSI'] < 30:\n",
    "        text += \"Th·ªã tr∆∞·ªùng ƒëang qu√° b√°n.\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fa2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# üíæ MEMORY + LLM DECISION MODULE (FinAgent Style)\n",
    "# ===============================================\n",
    "\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- C·∫•u h√¨nh LLM ---\n",
    "genai.configure(api_key=\"AIzaSyCOxyHaB3mLmknqN1GLlxDesTQpqFvhpzE\")  # ‚ö†Ô∏è thay b·∫±ng key th·∫≠t c·ªßa b·∫°n\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# =============================\n",
    "# üß† IMPROVED MULTI-TIER MEMORY\n",
    "# =============================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, sqlite3, json, numpy as np, time, os\n",
    "\n",
    "# --- Config ---\n",
    "_EMBED_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "_EMBED_DIM = 384\n",
    "_MEMORY_PATH = \"memory_store\"\n",
    "\n",
    "# T·∫°o folder l∆∞u tr·ªØ n·∫øu ch∆∞a c√≥\n",
    "os.makedirs(_MEMORY_PATH, exist_ok=True)\n",
    "\n",
    "def _normalize(vectors: np.ndarray):\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    return vectors / norms\n",
    "\n",
    "# --- Helper t·∫°o index v√† DB ---\n",
    "def _init_index_and_db(tier_name: str):\n",
    "    index_file = os.path.join(_MEMORY_PATH, f\"{tier_name}_index.faiss\")\n",
    "    db_file = os.path.join(_MEMORY_PATH, f\"{tier_name}_meta.db\")\n",
    "\n",
    "    # FAISS\n",
    "    try:\n",
    "        index = faiss.read_index(index_file)\n",
    "        print(f\"‚úÖ Loaded {tier_name} FAISS index.\")\n",
    "    except Exception:\n",
    "        index = faiss.IndexFlatIP(_EMBED_DIM)\n",
    "        print(f\"üÜï Created new {tier_name} FAISS index.\")\n",
    "\n",
    "    # SQLite\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS memory_meta (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        timestamp REAL,\n",
    "        summary TEXT,\n",
    "        action TEXT,\n",
    "        reason TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "    return index, conn, index_file\n",
    "\n",
    "# --- T·∫°o 3 t·∫ßng b·ªô nh·ªõ ---\n",
    "_short_index, _short_conn, _short_file = _init_index_and_db(\"short_term\")\n",
    "_medium_index, _medium_conn, _medium_file = _init_index_and_db(\"medium_term\")\n",
    "_long_index, _long_conn, _long_file = _init_index_and_db(\"long_term\")\n",
    "\n",
    "def add_memory(summary: str, action: str, reason: str, tier: str = \"short\"):\n",
    "    \"\"\"\n",
    "    Th√™m 1 m·∫´u nh·ªõ v√†o t·∫ßng t∆∞∆°ng ·ª©ng.\n",
    "    tier = 'short' | 'medium' | 'long'\n",
    "    \"\"\"\n",
    "    emb = _EMBED_MODEL.encode([summary]).astype(\"float32\")\n",
    "    emb = _normalize(emb)\n",
    "    ts = time.time()\n",
    "\n",
    "    # Ch·ªçn t·∫ßng\n",
    "    if tier == \"short\":\n",
    "        index, conn, file = _short_index, _short_conn, _short_file\n",
    "    elif tier == \"medium\":\n",
    "        index, conn, file = _medium_index, _medium_conn, _medium_file\n",
    "    else:\n",
    "        index, conn, file = _long_index, _long_conn, _long_file\n",
    "\n",
    "    base_id = index.ntotal\n",
    "    index.add(emb)\n",
    "    faiss.write_index(index, file)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        \"INSERT INTO memory_meta (id, timestamp, summary, action, reason) VALUES (?, ?, ?, ?, ?)\",\n",
    "        (base_id, ts, summary, action, reason)\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "def query_memory(query: str, tier: str = \"all\", k: int = 3):\n",
    "    \"\"\"\n",
    "    Truy v·∫•n memory theo t·∫ßng (short / medium / long / all)\n",
    "    \"\"\"\n",
    "    emb = _EMBED_MODEL.encode([query]).astype(\"float32\")\n",
    "    emb = _normalize(emb)\n",
    "    results = []\n",
    "\n",
    "    def _search(index, conn, label):\n",
    "        D, I = index.search(emb, k)\n",
    "        cur = conn.cursor()\n",
    "        tier_results = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            cur.execute(\"SELECT summary, action, reason, timestamp FROM memory_meta WHERE id=?\", (int(idx),))\n",
    "            row = cur.fetchone()\n",
    "            if row:\n",
    "                tier_results.append({\n",
    "                    \"tier\": label,\n",
    "                    \"summary\": row[0],\n",
    "                    \"action\": row[1],\n",
    "                    \"reason\": row[2],\n",
    "                    \"timestamp\": row[3],\n",
    "                    \"score\": float(score)\n",
    "                })\n",
    "        return tier_results\n",
    "\n",
    "    if tier == \"short\" or tier == \"all\":\n",
    "        results.extend(_search(_short_index, _short_conn, \"short\"))\n",
    "    if tier == \"medium\" or tier == \"all\":\n",
    "        results.extend(_search(_medium_index, _medium_conn, \"medium\"))\n",
    "    if tier == \"long\" or tier == \"all\":\n",
    "        results.extend(_search(_long_index, _long_conn, \"long\"))\n",
    "\n",
    "    # S·∫Øp x·∫øp k·∫øt qu·∫£ theo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·∫£m d·∫ßn\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    return results[:k]\n",
    "\n",
    "# =====================\n",
    "# ü§ñ ASK GEMINI (Decision)\n",
    "# =====================\n",
    "\n",
    "# Cache c·ª•c b·ªô ƒë·ªÉ tr√°nh g·ªçi l·∫°i c√πng 1 summary\n",
    "cache = {}\n",
    "\n",
    "def ask_gemini(summary: str, indicators: dict = None):\n",
    "    \"\"\"\n",
    "    Tool-augmented Decision:\n",
    "    LLM s·∫Ω s·ª≠ d·ª•ng c·∫£ th√¥ng tin t·ª´ Memory v√† c√°c ch·ªâ b√°o k·ªπ thu·∫≠t\n",
    "    ƒë·ªÉ ra quy·∫øt ƒë·ªãnh ch√≠nh x√°c h∆°n.\n",
    "    \"\"\"\n",
    "    # --- Ki·ªÉm tra cache ---\n",
    "    if summary in cache:\n",
    "        return cache[summary]\n",
    "\n",
    "    # --- Truy xu·∫•t b·ªëi c·∫£nh g·∫ßn nh·∫•t t·ª´ Memory ---\n",
    "    similar_cases = query_memory(summary, k=3)\n",
    "    if similar_cases:\n",
    "        context = \"\\n\".join([\n",
    "            f\"- {c['summary']} ‚Üí {c['action']} ({c['reason']})\"\n",
    "            for c in similar_cases\n",
    "        ])\n",
    "    else:\n",
    "        context = \"Kh√¥ng c√≥ d·ªØ li·ªáu t∆∞∆°ng t·ª± trong qu√° kh·ª©.\"\n",
    "\n",
    "    # --- Chu·∫©n b·ªã th√¥ng tin k·ªπ thu·∫≠t (n·∫øu c√≥) ---\n",
    "    tech_text = \"\"\n",
    "    if indicators:\n",
    "        tech_text = (\n",
    "            f\"Technical Indicators:\\n\"\n",
    "            f\"RSI: {indicators.get('RSI', 'N/A'):.2f}\\n\"\n",
    "            f\"MA20: {indicators.get('MA20', 'N/A'):.2f}\\n\"\n",
    "            f\"MA50: {indicators.get('MA50', 'N/A'):.2f}\\n\"\n",
    "        )\n",
    "        # N·∫øu c√≥ MACD:\n",
    "        if \"MACD\" in indicators:\n",
    "            tech_text += f\"MACD: {indicators['MACD']:.2f}\\n\"\n",
    "        if \"Signal\" in indicators:\n",
    "            tech_text += f\"MACD Signal: {indicators['Signal']:.2f}\\n\"\n",
    "\n",
    "    # 1Ô∏è‚É£ L·∫•y c√°c reflection g·∫ßn ƒë√¢y t·ª´ Memory\n",
    "    reflection_context = \"\"\n",
    "    recent_reflections = query_memory(\"reflection\", tier=\"medium\", k=3)\n",
    "    if recent_reflections:\n",
    "        reflection_context = \"\\n\".join([\n",
    "            f\"- {r['summary']} ‚Üí {r['reason']} (Tier: {r['tier'] if 'tier' in r else 'medium'})\"\n",
    "            for r in recent_reflections\n",
    "        ])\n",
    "    else:\n",
    "        reflection_context = \"No recent reflections available.\"\n",
    "\n",
    "    # 2Ô∏è‚É£ T·∫°o prompt ho√†n ch·ªânh cho Gemini\n",
    "    prompt = f\"\"\"\n",
    "B·∫°n l√† m·ªôt agent giao d·ªãch t√†i ch√≠nh c√≥ kh·∫£ nƒÉng t·ª± h·ªçc h·ªèi (financial trading agent with self-improvement).\n",
    "\n",
    "Nhi·ªám v·ª• c·ªßa b·∫°n:\n",
    "- Ph√¢n t√≠ch th√¥ng tin th·ªã tr∆∞·ªùng, c√°c ch·ªâ b√°o k·ªπ thu·∫≠t v√† kinh nghi·ªám qu√° kh·ª©.\n",
    "- D·ª±a v√†o d·ªØ li·ªáu b√™n d∆∞·ªõi, h√£y quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông: MUA, B√ÅN ho·∫∑c GI·ªÆ.\n",
    "- S·ª≠ d·ª•ng kinh nghi·ªám ph·∫£n chi·∫øu (reflection) ƒë·ªÉ tr√°nh l·∫∑p l·∫°i sai l·∫ßm, v√† t·∫≠n d·ª•ng nh·ªØng h√†nh ƒë·ªông hi·ªáu qu·∫£ tr∆∞·ªõc ƒë√¢y.\n",
    "\n",
    "Th√¥ng tin hi·ªán t·∫°i:\n",
    "{summary}\n",
    "\n",
    "{tech_text}\n",
    "\n",
    "Kinh nghi·ªám t∆∞∆°ng t·ª± trong qu√° kh·ª©:\n",
    "{context}\n",
    "\n",
    "Nh·ªØng ph·∫£n chi·∫øu g·∫ßn ƒë√¢y (ƒë√°nh gi√° k·∫øt qu·∫£ h√†nh ƒë·ªông tr∆∞·ªõc ƒë√¢y):\n",
    "{reflection_context}\n",
    "\n",
    "‚ö†Ô∏è Y√™u c·∫ßu b·∫Øt bu·ªôc:\n",
    "- To√†n b·ªô c√¢u tr·∫£ l·ªùi ph·∫£i b·∫±ng **ti·∫øng Vi·ªát t·ª± nhi√™n, r√µ r√†ng**.\n",
    "- Gi·∫£i th√≠ch ng·∫Øn g·ªçn l√Ω do (reason) li√™n quan ƒë·∫øn kinh nghi·ªám ho·∫∑c ch·ªâ b√°o k·ªπ thu·∫≠t.\n",
    "\n",
    "ƒê·ªãnh d·∫°ng ƒë·∫ßu ra b·∫Øt bu·ªôc:\n",
    "H√†nh ƒë·ªông: <MUA/B√ÅN/GI·ªÆ>\n",
    "L√Ω do: <Gi·∫£i th√≠ch ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # --- G·ªçi Gemini ---\n",
    "    try:\n",
    "        response = model.generate_content(prompt, generation_config={\"temperature\": 0.2})\n",
    "        text = response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è L·ªói g·ªçi Gemini: {e}\")\n",
    "        return \"HOLD\", f\"Error calling Gemini ({e})\"\n",
    "\n",
    "    # --- Ph√¢n t√≠ch ph·∫£n h·ªìi ---\n",
    "    match_action = re.search(r\"Action:\\s*(BUY|SELL|HOLD)\", text, re.IGNORECASE)\n",
    "    match_reason = re.search(r\"Reason:\\s*(.*)\", text, re.IGNORECASE)\n",
    "    action = match_action.group(1).upper() if match_action else \"HOLD\"\n",
    "    reason = match_reason.group(1).strip() if match_reason else \"No explanation provided.\"\n",
    "\n",
    "    # --- L∆∞u k·∫øt qu·∫£ ---\n",
    "    cache[summary] = (action, reason)\n",
    "    try:\n",
    "        add_memory(summary, action, reason)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u v√†o memory: {e}\")\n",
    "\n",
    "    return action, reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212601a",
   "metadata": {},
   "source": [
    "# ƒê√°nh gi√° s·ª©c kh·ªèe Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def performance_metrics(portfolio_values):\n",
    "    daily_returns = np.diff(portfolio_values) / portfolio_values[:-1]\n",
    "    mean_return = np.mean(daily_returns)\n",
    "    std_return = np.std(daily_returns)\n",
    "    \n",
    "    # 1. ARR\n",
    "    arr = (portfolio_values[-1] / portfolio_values[0]) ** (252 / len(daily_returns)) - 1\n",
    "    \n",
    "    # 2. Sharpe Ratio\n",
    "    sr = mean_return / std_return * np.sqrt(252)\n",
    "    \n",
    "    # 3. Max Drawdown\n",
    "    cum_max = np.maximum.accumulate(portfolio_values)\n",
    "    drawdowns = (portfolio_values - cum_max) / cum_max\n",
    "    mdd = np.min(drawdowns)\n",
    "    \n",
    "    # 4. Calmar Ratio\n",
    "    cr = arr / abs(mdd)\n",
    "    \n",
    "    # 5. Sortino Ratio\n",
    "    downside_std = np.std([r for r in daily_returns if r < 0])\n",
    "    sor = mean_return / downside_std * np.sqrt(252)\n",
    "    \n",
    "    # 6. Volatility\n",
    "    vol = std_return * np.sqrt(252)\n",
    "    \n",
    "    return {\n",
    "        \"ARR\": arr,\n",
    "        \"Sharpe\": sr,\n",
    "        \"Calmar\": cr,\n",
    "        \"Sortino\": sor,\n",
    "        \"MDD\": mdd,\n",
    "        \"Volatility\": vol\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6891d",
   "metadata": {},
   "source": [
    "# Ch·∫°y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33903c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Xu·∫•t b√°o c√°o th√†nh c√¥ng: FinAgent_Report.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === Cell thay th·∫ø: Ch·∫°y m√¥ ph·ªèng v√† xu·∫•t b√°o c√°o Excel ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Gi·∫£ ƒë·ªãnh: TradingEnv, build_market_summary, ask_gemini, performance_metrics, df t·ªìn t·∫°i trong notebook\n",
    "\n",
    "env = TradingEnv(df)\n",
    "state = env.reset()\n",
    "\n",
    "records = []  # l∆∞u nh·∫≠t k√Ω t·ª´ng ng√†y: Date, Action, Reason, Portfolio_Value, MA20, MA50, RSI\n",
    "\n",
    "while True:\n",
    "    # build summary t·ª´ state (theo notebook)\n",
    "    summary = build_market_summary(state)\n",
    "\n",
    "    # G·ªçi agent ‚Äî agent c√≥ th·ªÉ tr·∫£ action ho·∫∑c (action, reason)\n",
    "    try:\n",
    "        res = ask_gemini(summary)\n",
    "    except Exception as e:\n",
    "        # N·∫øu l·ªói g·ªçi LLM, t·∫°m fallback: HOLD (an to√†n) v√† reason n√™u l·ªói\n",
    "        action = \"HOLD\"\n",
    "        reason = f\"ask_gemini error: {e}\"\n",
    "    else:\n",
    "        # x·ª≠ l√Ω ki·ªÉu tr·∫£ v·ªÅ\n",
    "        if isinstance(res, tuple) or isinstance(res, list):\n",
    "            # (action, reason) ho·∫∑c (action,)...\n",
    "            action = res[0]\n",
    "            reason = res[1] if len(res) > 1 else \"\"\n",
    "        else:\n",
    "            action = res\n",
    "            reason = \"\"\n",
    "\n",
    "    # Th·ª±c hi·ªán b∆∞·ªõc tr√™n env\n",
    "    step_out = env.step(action)\n",
    "    if isinstance(step_out, tuple) and len(step_out) >= 3:\n",
    "        state, portfolio_value, done = step_out[0], step_out[1], step_out[2]\n",
    "    else:\n",
    "        raise RuntimeError(\"env.step() tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng b·∫•t th∆∞·ªùng; ki·ªÉm tra signature c·ªßa env.step\")\n",
    "\n",
    "# ================================\n",
    "# ü™û Low-level Reflection Step\n",
    "# ================================\n",
    "\n",
    "    def reflect_action(summary, action, reason, portfolio_values):\n",
    "        \"\"\"\n",
    "        ƒê√°nh gi√° hi·ªáu qu·∫£ h√†nh ƒë·ªông v·ª´a qua v√† sinh ra insight m·ªõi.\n",
    "        \"\"\"\n",
    "        if len(portfolio_values) < 2:\n",
    "            return None  # ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªß\n",
    "        change = portfolio_values[-1] - portfolio_values[-2]\n",
    "        pct_change = (change / portfolio_values[-2]) * 100 if portfolio_values[-2] != 0 else 0\n",
    "        if pct_change > 0:\n",
    "            performance = \"hi·ªáu qu·∫£ T·ªêT (+{:.2f}%)\".format(pct_change)\n",
    "        elif pct_change < 0:\n",
    "            performance = \"hi·ªáu qu·∫£ K√âM ({:.2f}%)\".format(pct_change)\n",
    "        else:\n",
    "            performance = \"kh√¥ng thay ƒë·ªïi\"\n",
    "    \n",
    "        reflection_text = (\n",
    "            f\"H√†nh ƒë·ªông {action} ƒë∆∞·ª£c th·ª±c hi·ªán sau market summary: [{summary[:80]}...] \"\n",
    "            f\"‚Üí {performance}. L√Ω do ban ƒë·∫ßu: {reason}\"\n",
    "        )\n",
    "        # L∆∞u reflection v√†o Memory ƒë·ªÉ Gemini h·ªçc t·ª´ k·∫øt qu·∫£ th·ª±c t·∫ø\n",
    "        try:\n",
    "            add_memory(reflection_text, action, performance)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u reflection v√†o memory: {e}\")\n",
    "\n",
    "    # G·ªçi reflection sau m·ªói b∆∞·ªõc\n",
    "    reflect_action(summary, action, reason, env.portfolio_values)\n",
    "    \n",
    "    # L·∫•y ng√†y hi·ªán t·∫°i an to√†n\n",
    "    current_date = None\n",
    "    # ∆∞u ti√™n l·∫•y t·ª´ env n·∫øu c√≥\n",
    "    if hasattr(env, \"current_step\"):\n",
    "        # c·ªë g·∫Øng l·∫•y ng√†y t·ª´ df theo current_step\n",
    "        idx = max(0, min(env.current_step, len(df)-1))\n",
    "        current_row = df.iloc[idx]\n",
    "        current_date = pd.to_datetime(current_row[\"Date\"])\n",
    "    else:\n",
    "        # fallback: n·∫øu state l√† dict c√≥ 'Date'\n",
    "        if isinstance(state, dict) and \"Date\" in state:\n",
    "            current_date = pd.to_datetime(state[\"Date\"])\n",
    "        else:\n",
    "            # fallback chung: n·∫øu df c√≥ c·ªôt Date, l·∫•y theo s·ªë b·∫£n ghi ƒë√£ l∆∞u\n",
    "            if len(records) < len(df):\n",
    "                current_date = pd.to_datetime(df.iloc[len(records)][\"Date\"])\n",
    "            else:\n",
    "                current_date = pd.to_datetime(df[\"Date\"].iloc[-1])\n",
    "\n",
    "    # t√¨m h√†ng df t∆∞∆°ng ·ª©ng v·ªõi current_date (so s√°nh normalize ƒë·ªÉ tr√°nh mismatch v·ªÅ time)\n",
    "    sel = df[pd.to_datetime(df[\"Date\"]).dt.normalize() == pd.to_datetime(current_date).normalize()]\n",
    "    if sel.empty:\n",
    "        # n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c b·∫±ng equality, ch·ªçn d√≤ng b·∫±ng index t∆∞∆°ng ·ª©ng n·∫øu env cung c·∫•p current_step\n",
    "        if hasattr(env, \"current_step\"):\n",
    "            row = df.iloc[max(0, min(env.current_step, len(df)-1))]\n",
    "        else:\n",
    "            # an to√†n: t·∫°o row r·ªóng\n",
    "            row = pd.Series({\"MA20\": np.nan, \"MA50\": np.nan, \"RSI\": np.nan})\n",
    "    else:\n",
    "        row = sel.iloc[0]\n",
    "\n",
    "    ma20 = row.get(\"MA20\", np.nan)\n",
    "    ma50 = row.get(\"MA50\", np.nan)\n",
    "    rsi  = row.get(\"RSI\", np.nan)\n",
    "\n",
    "    # l∆∞u record\n",
    "    records.append(OrderedDict([\n",
    "        (\"Date\", pd.to_datetime(current_date)),\n",
    "        (\"Action\", action),\n",
    "        (\"Reason\", reason),\n",
    "        (\"Portfolio_Value\", portfolio_value),\n",
    "        (\"MA20\", ma20),\n",
    "        (\"MA50\", ma50),\n",
    "        (\"RSI\", rsi),\n",
    "    ]))\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "# Sau khi loop k·∫øt th√∫c: t√≠nh metrics (l·ªçc NaN trong portfolio_values)\n",
    "pv = np.array(env.portfolio_values, dtype=float)\n",
    "pv = pv[~np.isnan(pv)] if pv.size>0 else pv\n",
    "\n",
    "metrics = performance_metrics(pv)  # dict: ARR, Sharpe, Calmar, Sortino, MDD, Volatility\n",
    "\n",
    "# Chu·∫©n b·ªã DataFrame cho export\n",
    "df_actions = pd.DataFrame(records).sort_values(\"Date\").reset_index(drop=True)\n",
    "df_metrics = pd.DataFrame(list(metrics.items()), columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "# Xu·∫•t file Excel (2 sheet)\n",
    "output_file = \"FinAgent_Report.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "    df_actions.to_excel(writer, sheet_name=\"Actions & Portfolio\", index=False)\n",
    "    df_metrics.to_excel(writer, sheet_name=\"Performance Metrics\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Xu·∫•t b√°o c√°o th√†nh c√¥ng: {output_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
